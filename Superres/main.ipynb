{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import random\n",
    "from tensorflow.python.data.experimental import AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../../Data/DIV2K_train_HR/DIV2K_train_HR/'\n",
    "valid_dir = '../../Data/DIV2K_valid_HR/DIV2K_valid_HR/'\n",
    "def prepare_data(data_dir=train_dir):\n",
    "    sizes = []\n",
    "    for fl in os.listdir(data_dir):\n",
    "        img = cv2.imread(os.path.join(train_dir, fl))\n",
    "        if img.shape not in sizes:\n",
    "            sizes.append(img.shape)\n",
    "    return sizes\n",
    "\n",
    "def download_from_wallhaven(url = r'https://wallhaven.cc/api/v1/search?categories=111&purity=111&atleast=1920x1080&sorting=views&order=desc&apikey=VIkPSqUeNeL2Q5PZh6FAWWW4aSz3IMYD'\n",
    ", from_page=1, output_dir='../../Data/Wallhaven/', total_images=1000):\n",
    "    if os.path.exists(output_dir) == False:\n",
    "        os.makedirs(output_dir)\n",
    "    dloaded = 0\n",
    "    while dloaded < total_images:\n",
    "        _url = url+r'&page='+str(from_page)\n",
    "        from_page += 1\n",
    "        page = requests.get(_url)\n",
    "        b = json.loads(page.content)\n",
    "        if b == None or len(b) == 0:\n",
    "            raise Exception(\"found page len to be 0\")\n",
    "        \n",
    "        for i in range(len(b['data'])):\n",
    "            if dloaded >= total_images:\n",
    "                break\n",
    "            url_to_dload = b['data'][i]['path'] \n",
    "            print(url_to_dload)\n",
    "            resp = requests.get(url_to_dload, allow_redirects=True, stream=True).raw\n",
    "            img = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "            image_name = url_to_dload.split('/')[-1]\n",
    "            img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
    "            cv2.imwrite(output_dir+image_name, img)\n",
    "            dloaded += 1\n",
    "    \n",
    "def prepare_csv(csv_name='train.csv', folders=[], seed=42):\n",
    "    fs = []\n",
    "    for folder in folders:\n",
    "        for file in os.listdir(folder):\n",
    "            fl = os.path.join(folder, file)\n",
    "            if fl not in fs:\n",
    "                fs.append(fl)\n",
    "    random.seed(seed)\n",
    "    random.shuffle(fs)\n",
    "    data = {'path': fs}\n",
    "    df = pd.DataFrame(data=data)\n",
    "    df.to_csv(csv_name)\n",
    "# download_from_wallhaven(from_page=1, output_dir='../../Data/Wallhaven/', total_images=1000)    \n",
    "# download_from_wallhaven(from_page=1000, output_dir='../../Data/Wallhaven_test/', total_images=100)\n",
    "# prepare_csv('train.csv', folders=['../../Data/Wallhaven/', '../../Data/DIV2K_train_HR/DIV2K_train_HR/'])\n",
    "# prepare_csv('test.csv', folders=['../../Data/Wallhaven_test/', '../../Data/DIV2K_valid_HR/DIV2K_valid_HR/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\somer\\AppData\\Local\\Temp/ipykernel_4940/1676159560.py:3: get_memory_usage (from tensorflow.python.framework.config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.config.experimental.get_memory_info(device)['current'] instead.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "  print(tf.config.experimental.get_memory_usage('GPU:0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_shuffle(scale):\n",
    "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
    "\n",
    "def resnet_block(x_in, filters=64, kernel=3, scaling=.1):\n",
    "    x = keras.layers.Conv2D(filters, kernel, padding='same')(x_in)\n",
    "    x = keras.layers.Conv2D(filters, kernel, padding='same')(x)\n",
    "    if scaling != 0:\n",
    "        x = keras.layers.Lambda(lambda x: x * scaling)(x)\n",
    "    x = keras.layers.Add()([x_in, x])\n",
    "    \n",
    "def up_sample(x, filters=64, kernel=3, scaling=1):\n",
    "    factor = 2\n",
    "    name='scale2'\n",
    "    if scaling==3:\n",
    "        factor = 3\n",
    "        name='scale3'\n",
    "    x = keras.layers.Conv2D(filters * (factor ** 2), kernel, padidng='same', name=name)(x)\n",
    "    return keras.layers.Lambda(pixel_shuffle(scaling))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel, scaling=0):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(filters, kernel, padding='same', activation='selu')\n",
    "        self.conv2 = keras.layers.Conv2D(filters, kernel, padding='same')\n",
    "        self.scaler = None\n",
    "        self.scaling = tf.constant(scaling)\n",
    "        if scaling == None or scaling == 0:\n",
    "            self.scaling = 1\n",
    "        self.scaler = keras.layers.Lambda(lambda x: x * scaling)\n",
    "        self.c = keras.layers.Add()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.cond(self.scaling > 0,lambda: self.scaler(x),lambda: tf.identity(x))\n",
    "        x = self.c([x, inputs])\n",
    "        return x\n",
    "        \n",
    "class UpSampler(tf.keras.Model):\n",
    "    def __init__(self, filters=64, kernel=3, scaling=0, *args, **kwargs):\n",
    "        super(UpSampler, self).__init__(*args, **kwargs)\n",
    "        self.layers_ = []\n",
    "        factor = 2\n",
    "        if scaling > 1:\n",
    "            if scaling == 3:\n",
    "                factor = 3\n",
    "            self.layers_.append(keras.layers.Conv2D(filters * (factor ** 2), kernel, padding='same'))\n",
    "            self.layers_.append(keras.layers.Lambda(pixel_shuffle(factor)))\n",
    "            \n",
    "            if scaling == 4:\n",
    "                self.layers_.append(keras.layers.Conv2D(filters * (factor ** 2), kernel, padding='same'))\n",
    "                self.layers_.append(keras.layers.Lambda(pixel_shuffle(factor)))\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers_:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EDSR(tf.keras.Model):\n",
    "    def __init__(self, filters, res_blocks, kernel_size=3, scaling=2, res_block_scaling=0, rgb_mean=np.array([0.4488, 0.4371, 0.4040]) * 255) -> None:\n",
    "        super(EDSR, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_res_blocks = res_blocks\n",
    "        self.res_block_scaling = res_block_scaling\n",
    "        self.rgb_mean = rgb_mean\n",
    "        self.scaling = scaling\n",
    "        \n",
    "        # self.input = keras.layers.Input((None, None, 3))\n",
    "        self.normalizer = keras.layers.Lambda(lambda x: (x - rgb_mean) / 127.5)\n",
    "        self.conv1 = keras.layers.Conv2D(self.filters, self.kernel_size, padding='same')\n",
    "        self.res_blocks = []\n",
    "        for i in range (self.num_res_blocks):\n",
    "            self.res_blocks.append(ResnetBlock(self.filters, self.kernel_size, self.res_block_scaling))\n",
    "        self.conv2 = keras.layers.Conv2D(self.filters, self.kernel_size, padding='same')    \n",
    "        self.add1 = keras.layers.Add()\n",
    "        \n",
    "        self.upsampler1 = UpSampler(self.filters, self.kernel_size, self.scaling)\n",
    "        self.conv3 = keras.layers.Conv2D(3, 3, padding='same')\n",
    "        \n",
    "        self.denormalizer = keras.layers.Lambda(lambda x: (x * rgb_mean) + 127.5)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # print(inputs.shape)\n",
    "        x = self.normalizer(inputs)\n",
    "        # print(x.shape)\n",
    "        x = b = self.conv1(x)\n",
    "        # print(x.shape, b.shape)\n",
    "        for block in self.res_blocks:\n",
    "            b = block(b)\n",
    "        b = self.conv2(b)\n",
    "        x = self.add1([x, b])\n",
    "        x = self.upsampler1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.denormalizer(x)\n",
    "        \n",
    "        # i = tf.constant(0)\n",
    "        # cond = lambda i, _: i < self.num_res_blocks\n",
    "        # body = lambda i, x: (self.res_blocks[i](x), tf.add(i, 1))\n",
    "        # _, x = tf.while_loop(cond,lambda i, x: tf.identity(x), [i, x], swap_memory=True, parallel_iterations=1)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "\n",
    "def psnr(x1, x2):\n",
    "    return tf.image.psnr(x1, x2, max_val=255)\n",
    "\n",
    "def resolve(model, lr_batch):\n",
    "    lr_batch = tf.cast(lr_batch, tf.float32)\n",
    "    sr_batch = model(lr_batch)\n",
    "    sr_batch = tf.clip_by_value(sr_batch, 0, 255)\n",
    "    sr_batch = tf.round(sr_batch)\n",
    "    sr_batch = tf.cast(sr_batch, tf.uint8)\n",
    "    return sr_batch\n",
    "\n",
    "def evaluate(model, dataset):\n",
    "    psnr_values = []\n",
    "    for lr, hr in dataset:\n",
    "        sr = resolve(model, lr)\n",
    "        psnr_value = psnr(hr, sr)[0]\n",
    "        psnr_values.append(psnr_value)\n",
    "    return tf.reduce_mean(psnr_values)\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, loss, learning_rate, checkpoint_dr='./checkpoints/', model_name = \"\") -> None:\n",
    "        super().__init__()\n",
    "        self.now = time.time()\n",
    "        self.loss = loss\n",
    "        self.checkpoint = tf.train.Checkpoint\n",
    "        self.model = model\n",
    "        \n",
    "        self.checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                              psnr=tf.Variable(-1.0),\n",
    "                                              optimizer=keras.optimizers.Adam(learning_rate),\n",
    "                                              model=model)\n",
    "        if model_name != \"\":\n",
    "            try:\n",
    "                os.makedirs(checkpoint_dr+model_name)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            checkpoint_dr = os.path.join(checkpoint_dr, model_name)\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(checkpoint=self.checkpoint,\n",
    "                                                             directory=checkpoint_dr,\n",
    "                                                             max_to_keep=3)\n",
    "\n",
    "        self.restore()\n",
    "    # @property\n",
    "    # def model(self):\n",
    "    #     return self.checkpoint.model\n",
    "    \n",
    "    def train(self, train_ds, valid_ds, epochs, steps, eval_every=1000, save_best_only=False):\n",
    "        loss_metric = keras.metrics.Mean()\n",
    "        self.now = time.perf_counter()\n",
    "        for lr, hr in train_ds.take(steps - self.checkpoint.step.numpy()):\n",
    "            # print(lr.shape, hr.shape, steps - self.checkpoint.step.numpy())\n",
    "            self.checkpoint.step.assign_add(1)\n",
    "            step = self.checkpoint.step.numpy()\n",
    "            loss = self.train_step(lr, hr)\n",
    "            loss_metric(loss)\n",
    "            # print(step + 1, eval_every, step + 1 % eval_every)\n",
    "            if (step + 1) % eval_every == 0:\n",
    "                print('validation:: ')\n",
    "                loss_val = loss_metric.result()\n",
    "                loss_metric.reset_states()\n",
    "                \n",
    "                psnr_val = self.evaluate(valid_ds.take(1))\n",
    "                \n",
    "                duration = time.perf_counter() - self.now\n",
    "                print(f'{step}/{steps}: loss = {loss_val.numpy():.3f}, PSNR = {psnr_val.numpy():3f} ({duration:.2f}s)')\n",
    "\n",
    "                if save_best_only and psnr_val <= self.checkpoint.psnr:\n",
    "                    self.now = time.perf_counter()\n",
    "                    continue\n",
    "\n",
    "                self.checkpoint.psnr = psnr_val\n",
    "                self.checkpoint_manager.save()\n",
    "\n",
    "                self.now = time.perf_counter()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def train_step(self, lr, hr):\n",
    "        with tf.GradientTape() as tape:\n",
    "            lr = tf.cast(lr, tf.float32)\n",
    "            hr = tf.cast(hr, tf.float32)\n",
    "            \n",
    "            sr = self.checkpoint.model(lr, training=True)\n",
    "            loss = self.loss(hr, sr)\n",
    "        grads = tape.gradient(loss, self.checkpoint.model.trainable_variables)\n",
    "        self.checkpoint.optimizer.apply_gradients(zip(grads, self.checkpoint.model.trainable_variables))\n",
    "        return loss\n",
    "        \n",
    "    def evaluate(self, dataset):\n",
    "        return evaluate(self.checkpoint.model, dataset)\n",
    "    \n",
    "    def restore(self):\n",
    "        if self.checkpoint_manager.latest_checkpoint:\n",
    "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "            print(f'Model restored from checkpoint at step {self.checkpoint.step.numpy()}.')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, csv='train.csv', scale=2, subset='train', downgrade='bicubic', dr='', batch_size=8, split=.8, epochs=50, crop_size=96) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.crop_size = crop_size\n",
    "        self.epochs = epochs\n",
    "        self.downgrades = ['bicubic', 'unknown', 'mild', 'difficult']\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self._scales = [2,3,4,8]\n",
    "        if scale in self._scales:\n",
    "            self.scale=scale\n",
    "        else:\n",
    "            raise ValueError(f'scale must be in ${self.scales}')\n",
    "                \n",
    "        \n",
    "        len_df = len(self.df)\n",
    "        if subset == 'train':\n",
    "            self.image_ids = range(1, int(len_df * split))\n",
    "        elif subset == 'valid':\n",
    "            self.image_ids = range(int(len_df * split), len_df)\n",
    "        else:\n",
    "            raise ValueError(\"subset must be train or valid\")\n",
    "        \n",
    "        self.subset = subset\n",
    "        self.downgrade = downgrade\n",
    "        self.images_dr = dr\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def dataset(self, random_transform):\n",
    "        ds = tf.data.Dataset.zip((self.create_dataset(self.df.path.to_list(), self.get_path(True), True), self.create_dataset(self.df.path.to_list(), self.get_path(False), False)))\n",
    "        if random_transform == True:\n",
    "            ds = ds.map(lambda lr, hr: random_crop(lr, hr, self.crop_size, self.scale), num_parallel_calls=AUTOTUNE)\n",
    "            ds = ds.map(random_rotate, num_parallel_calls=AUTOTUNE)\n",
    "            ds = ds.map(random_flip, num_parallel_calls=AUTOTUNE)\n",
    "            ds = ds.map(random_brightness, num_parallel_calls=AUTOTUNE)\n",
    "        ds = ds.shuffle(self.batch_size, reshuffle_each_iteration=True)\n",
    "\n",
    "        ds = ds.batch(self.batch_size)\n",
    "        ds = ds.repeat(self.epochs)\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "        return ds\n",
    "        \n",
    "    def get_low_res(self, file):\n",
    "            splt = file.split('/')\n",
    "            if 'HR' in splt[-2]:\n",
    "                splt[-2] = splt[-2][:-2]\n",
    "            splt[-2] += f'LR_{self.subset}_{self.scale}x'\n",
    "            return '/'.join(splt)\n",
    "    \n",
    "    def create_dataset(self, files, cache, lr=False):\n",
    "        if lr == True:\n",
    "            ##\n",
    "            # self.prepare_low_res()\n",
    "            ##\n",
    "            pass\n",
    "            \n",
    "            files = [(lambda x: self.get_low_res(x))(x) for x in files]\n",
    "        ds = tf.data.Dataset.from_tensor_slices(files).map(tf.io.read_file)\n",
    "        ds = ds.map(lambda x: tf.image.decode_png(x, 3), num_parallel_calls=AUTOTUNE)\n",
    "        ds.cache(filename=tf.convert_to_tensor(os.getcwd()+'\\\\'+self.subset+'_'+str(self.scale)+'.cache', dtype=tf.string))\n",
    "        for _ in ds:\n",
    "            pass\n",
    "        return ds\n",
    "    def get_path(self, is_lr=False):\n",
    "        r = 'LR' if is_lr == True else 'HR'\n",
    "        return f'{r}_{self.subset}_{self.scale}x'\n",
    "    def prepare_low_res(self): \n",
    "        \n",
    "        fls = self.df.path.to_list()\n",
    "        \n",
    "        for file in fls:\n",
    "            # print(file)\n",
    "            img = tf.convert_to_tensor(cv2.imread(file), dtype=tf.uint8)\n",
    "            img = tf.image.resize(img, (img.shape[0]//self.scale + (1 if img.shape[0] % 2 != 0 else 0), img.shape[1]//self.scale + (1 if img.shape[1] % 2 != 0 else 0)), tf.image.ResizeMethod.BICUBIC).numpy()\n",
    "            #similar to get lr func\n",
    "            splt = file.split('/')\n",
    "            if 'HR' in splt[-2]:\n",
    "                splt[-2] = splt[-2][:-2]\n",
    "            splt[-2] += f'LR_{self.subset}_{self.scale}x'\n",
    "            spl = splt[:-1]\n",
    "            if not os.path.exists('/'.join(spl)):\n",
    "                os.mkdir('/'.join(spl))\n",
    "            fl = '/'.join(splt)\n",
    "            \n",
    "            # print(fl)\n",
    "            cv2.imwrite(fl, img)\n",
    "    # def \n",
    "        \n",
    "    \n",
    "def random_flip(lr_img, hr_img):\n",
    "    rn = tf.random.uniform(shape=(), maxval=1)\n",
    "    return tf.cond(rn < .5, \n",
    "                   lambda: (lr_img, hr_img), \n",
    "                   lambda: (tf.image.flip_left_right(lr_img), tf.image.flip_left_right(hr_img))\n",
    "                   )\n",
    "    \n",
    "def random_brightness(lr_img, hr_img):\n",
    "    rn = tf.random.uniform(shape=(), maxval=1)\n",
    "    shift = tf.random.uniform(shape=(), minval=-.2, maxval=.2)\n",
    "    \n",
    "    return tf.cond(rn < .5, \n",
    "                   lambda: (lr_img, hr_img), \n",
    "                   lambda: (tf.image.adjust_brightness(lr_img, shift), tf.image.adjust_brightness(hr_img, shift))\n",
    "                   )\n",
    "    \n",
    "\n",
    "def random_rotate(lr_img, hr_img):\n",
    "    rn = tf.random.uniform(shape=(), maxval=4, dtype=tf.int32)\n",
    "    return tf.image.rot90(lr_img, rn), tf.image.rot90(hr_img, rn)\n",
    "\n",
    "def random_crop(lr_img, hr_img, hr_crop_size=96, scale=2):\n",
    "    lr_crop_size = hr_crop_size // scale\n",
    "    lr_img_shp = tf.shape(lr_img)[:2]\n",
    "    \n",
    "    lr_w = tf.random.uniform(shape=(), maxval=lr_img_shp[1] - lr_crop_size + 1, dtype=tf.int32)\n",
    "    lr_h = tf.random.uniform(shape=(), maxval=lr_img_shp[0] - lr_crop_size + 1, dtype=tf.int32)\n",
    "    if lr_w > 3:\n",
    "        lr_w -=3\n",
    "    if lr_h > 3:\n",
    "        lr_h -= 3\n",
    "    hr_w = lr_w * scale\n",
    "    hr_h = lr_h * scale\n",
    "    \n",
    "    # print(lr_h, lr_h + lr_crop_size, lr_w, lr_w+ lr_crop_size)\n",
    "    # print(hr_h,hr_h + hr_crop_size, hr_w, hr_w+ hr_crop_size)\n",
    "    lr_img_cropped = lr_img[lr_h:lr_h + lr_crop_size, lr_w: lr_w+ lr_crop_size]\n",
    "    hr_img_cropped = hr_img[hr_h:hr_h + hr_crop_size, hr_w: hr_w+ hr_crop_size]\n",
    "    \n",
    "    return lr_img_cropped, hr_img_cropped    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = Dataset(subset='train', scale=4, epochs=-1, crop_size=96*2)\n",
    "train_ds = tr_ds.dataset(True)\n",
    "val_ds = Dataset(subset='valid', scale=4, batch_size=1, crop_size=256, epochs=-1)\n",
    "valid_ds = val_ds.dataset(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: './checkpoints4x/res24_rmse'\n",
      "Model restored from checkpoint at step 4999.\n",
      "validation:: \n",
      "9999/1000000: loss = 13.751, PSNR = 28.835882 (982.17s)\n",
      "validation:: \n",
      "14999/1000000: loss = 17.294, PSNR = 33.131020 (968.08s)\n",
      "validation:: \n",
      "19999/1000000: loss = 13.459, PSNR = 27.726410 (935.30s)\n",
      "validation:: \n",
      "24999/1000000: loss = 18.242, PSNR = 28.966898 (982.68s)\n",
      "validation:: \n",
      "29999/1000000: loss = 16.793, PSNR = 24.669607 (981.53s)\n",
      "validation:: \n",
      "34999/1000000: loss = 13.420, PSNR = 22.958891 (934.22s)\n",
      "validation:: \n",
      "39999/1000000: loss = 15.807, PSNR = 29.061581 (947.92s)\n",
      "validation:: \n",
      "44999/1000000: loss = 13.427, PSNR = 31.028515 (981.09s)\n",
      "validation:: \n",
      "49999/1000000: loss = 16.006, PSNR = 28.281641 (954.91s)\n",
      "validation:: \n",
      "54999/1000000: loss = 17.365, PSNR = 28.995903 (954.54s)\n",
      "validation:: \n",
      "59999/1000000: loss = 13.332, PSNR = 29.909019 (923.90s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4940/4041418074.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEDSR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0medsr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_mean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPiecewiseConstantDecay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboundaries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_dr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./checkpoints4x/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"res24_rmse\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0medsr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4940/531588856.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_ds, valid_ds, epochs, steps, eval_every, save_best_only)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mloss_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;31m# print(step + 1, eval_every, step + 1 % eval_every)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4940/531588856.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, lr, hr)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    663\u001b[0m             f\"strategy={strategy}.\")\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m       \u001b[0mapply_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_unaggregated_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_prepare\u001b[1;34m(self, var_list)\u001b[0m\n\u001b[0;32m    947\u001b[0m       \u001b[0mapply_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\keras\\optimizer_v2\\adam.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[1;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_prepare_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[0mlocal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[1;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[0;32m    953\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_prepare_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"learning_rate\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hyper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m       \u001b[0mlr_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decayed_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m       \u001b[0mapply_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lr_t\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_decayed_lr\u001b[1;34m(self, var_dtype)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m       \u001b[0mlocal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m       \u001b[0mlr_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_decay\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[0mlocal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\keras\\optimizer_v2\\learning_rate_schedule.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, step)\u001b[0m\n\u001b[0;32m    288\u001b[0m       \u001b[1;31m# exclusive and exhaustive, but tf.case requires it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m       \u001b[0mdefault\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_fn_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclusive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1096\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mcase_v2\u001b[1;34m(pred_fn_pairs, default, exclusive, strict, name)\u001b[0m\n\u001b[0;32m   3483\u001b[0m                \u001b[0mcallable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3484\u001b[0m   \"\"\"\n\u001b[1;32m-> 3485\u001b[1;33m   return _case_helper(\n\u001b[0m\u001b[0;32m   3486\u001b[0m       \u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3487\u001b[0m       \u001b[0mpred_fn_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_case_helper\u001b[1;34m(cond_fn, pred_fn_pairs, default, exclusive, name, allow_python_preds, **cond_kwargs)\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexclusive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3277\u001b[0m       with ops.control_dependencies([\n\u001b[1;32m-> 3278\u001b[1;33m           _assert_at_most_n_true(\n\u001b[0m\u001b[0;32m   3279\u001b[0m               predicates, n=1, msg=\"Input error: exclusive=True\")\n\u001b[0;32m   3280\u001b[0m       ]):\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_assert_at_most_n_true\u001b[1;34m(predicates, n, msg)\u001b[0m\n\u001b[0;32m   3122\u001b[0m   \"\"\"\n\u001b[0;32m   3123\u001b[0m   \u001b[0mpreds_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"preds_c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3124\u001b[1;33m   num_true_conditions = math_ops.reduce_sum(\n\u001b[0m\u001b[0;32m   3125\u001b[0m       math_ops.cast(preds_c, dtypes.int32), name=\"num_true_conds\")\n\u001b[0;32m   3126\u001b[0m   condition = math_ops.less_equal(num_true_conditions,\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1096\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2291\u001b[0m   \"\"\"\n\u001b[0;32m   2292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2293\u001b[1;33m   return reduce_sum_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0m\u001b[0;32m   2294\u001b[0m                               _ReductionDims(input_tensor, axis))\n\u001b[0;32m   2295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_sum_with_dims\u001b[1;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[0;32m   2303\u001b[0m   return _may_reduce_to_scalar(\n\u001b[0;32m   2304\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2305\u001b[1;33m       gen_math_ops._sum(input_tensor, dims, keepdims, name=name))\n\u001b[0m\u001b[0;32m   2306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Python\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[0;32m  11189\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11190\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11191\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m  11192\u001b[0m         _ctx, \"Sum\", name, input, axis, \"keep_dims\", keep_dims)\n\u001b[0;32m  11193\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# os.makedirs('checkpoints4x')\n",
    "K = keras.backend\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "    \n",
    "model = EDSR(128, 24, scaling=4)\n",
    "edsr = Trainer(model, root_mean_squared_error, learning_rate=keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=[200000], values=[1e-3, 1e-5]), checkpoint_dr='./checkpoints4x/', model_name=\"res24_rmse\")\n",
    "edsr.train(train_ds, valid_ds.take(100), 40, 1000000, 5000, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edsr.model.save_weights('weights24_4', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x19f170e86a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = EDSR(128, 24, scaling=4)\n",
    "# model.load_weights('weights24_4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "full = '../../Data/DIV2K_train_HR/DIV2K_train_HR/0180.png'\n",
    "pt = '../../Data/DIV2K_train_HR/DIV2K_train_LR_train_4x/0180.png'\n",
    "lr = cv2.imread(pt)\n",
    "fimg = cv2.imread(full)\n",
    "with tf.device('/cpu:0'):\n",
    "    sr =  resolve(model, tf.expand_dims(lr, axis=0))[0]\n",
    "plt.figure(figsize=(20, 10))\n",
    "images = [lr, sr, fimg]\n",
    "titles = ['LR', f'SR (x{sr.shape[0] // lr.shape[0]})']\n",
    "for i, (img, title) in enumerate(zip(images, titles)):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "cv2.imwrite('lr.png', lr)\n",
    "cv2.imwrite('sr2.png', sr.numpy())\n",
    "cv2.imwrite('fr.png', fimg)\n",
    "cv2.imwrite('up.png', cv2.resize(lr, (fimg.shape[1], fimg.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"a\", lr)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('lr.png', lr)\n",
    "cv2.imwrite('sr.png', sr.numpy())\n",
    "cv2.imwrite('fr.png', fimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[82, 71, 68],\n",
       "        [83, 69, 68],\n",
       "        [84, 70, 68],\n",
       "        ...,\n",
       "        [85, 70, 67],\n",
       "        [85, 72, 68],\n",
       "        [84, 72, 69]],\n",
       "\n",
       "       [[83, 69, 67],\n",
       "        [83, 70, 68],\n",
       "        [84, 69, 68],\n",
       "        ...,\n",
       "        [84, 71, 68],\n",
       "        [84, 72, 69],\n",
       "        [85, 72, 68]],\n",
       "\n",
       "       [[83, 68, 67],\n",
       "        [83, 68, 68],\n",
       "        [83, 68, 68],\n",
       "        ...,\n",
       "        [85, 72, 68],\n",
       "        [85, 72, 69],\n",
       "        [86, 74, 69]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[37, 37, 57],\n",
       "        [37, 39, 59],\n",
       "        [37, 38, 60],\n",
       "        ...,\n",
       "        [29, 12, 55],\n",
       "        [30, 14, 54],\n",
       "        [31, 15, 54]],\n",
       "\n",
       "       [[37, 39, 57],\n",
       "        [38, 40, 59],\n",
       "        [39, 41, 61],\n",
       "        ...,\n",
       "        [30, 15, 55],\n",
       "        [31, 17, 54],\n",
       "        [31, 19, 53]],\n",
       "\n",
       "       [[39, 40, 57],\n",
       "        [38, 40, 59],\n",
       "        [39, 40, 61],\n",
       "        ...,\n",
       "        [30, 14, 55],\n",
       "        [30, 17, 54],\n",
       "        [34, 22, 52]]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
