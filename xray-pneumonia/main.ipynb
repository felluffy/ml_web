{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from time import time\n",
    "from itertools import chain\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "\n",
    "from vit_keras import  vit, utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    validation_split=.3,\n",
    "    zoom_range=.2,\n",
    "    rotation_range=.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    # brightness_range=(.8, 1.2,),\n",
    "    # fill_mode='constant',\n",
    "    # cval=0,\n",
    ")\n",
    "\n",
    "\n",
    "train_dr =  'D:/Projects/Papers/xray-pneumonia/chest_xray/train'\n",
    "valid_dr = 'D:/Projects/Papers/xray-pneumonia/chest_xray/val'\n",
    "test_dr = 'D:/Projects/Papers/xray-pneumonia/chest_xray/test'\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "train_gen = datagen.flow_from_directory(directory=train_dr, batch_size=batch_size, class_mode='categorical', target_size=(224, 224), shuffle=True, seed=42)\n",
    "\n",
    "valid_gen = datagen.flow_from_directory(directory=valid_dr, batch_size=batch_size//4, class_mode='categorical', target_size=(224, 224), shuffle=True, seed=42)\n",
    "\n",
    "test_gen = datagen.flow_from_directory(directory=test_dr, batch_size=batch_size//4, class_mode='categorical', target_size=(224, 224), shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=.25, patience=5, verbose=1)\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=9, verbose=1, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\n",
    "    filepath = './saved_model/checkpoint/',\n",
    "    save_weights_only = True,\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'min',\n",
    "    save_best_only = True\n",
    ")\n",
    "\n",
    "callbacks = [reduce_lr, early_stopping, ckpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\vit_keras\\utils.py:81: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = vit.vit_b16(\n",
    "                    image_size=(224, 224), \n",
    "                    classes=2,\n",
    "                    activation='softmax', \n",
    "                    include_top=True, \n",
    "                    pretrained=True,\n",
    "                    pretrained_top = False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vit-b16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " embedding (Conv2D)          (None, 14, 14, 768)       590592    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 196, 768)          0         \n",
      "                                                                 \n",
      " class_token (ClassToken)    (None, 197, 768)          768       \n",
      "                                                                 \n",
      " Transformer/posembed_input   (None, 197, 768)         151296    \n",
      " (AddPositionEmbs)                                               \n",
      "                                                                 \n",
      " Transformer/encoderblock_0   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_1   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_2   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_3   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_4   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_5   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_6   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_7   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_8   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_9   ((None, 197, 768),       7087872   \n",
      " (TransformerBlock)           (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_10  ((None, 197, 768),       7087872   \n",
      "  (TransformerBlock)          (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoderblock_11  ((None, 197, 768),       7087872   \n",
      "  (TransformerBlock)          (None, 12, None, None))            \n",
      "                                                                 \n",
      " Transformer/encoder_norm (L  (None, 197, 768)         1536      \n",
      " ayerNormalization)                                              \n",
      "                                                                 \n",
      " ExtractToken (Lambda)       (None, 768)               0         \n",
      "                                                                 \n",
      " head (Dense)                (None, 2)                 1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,800,194\n",
      "Trainable params: 85,800,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "652/652 [==============================] - 161s 226ms/step - loss: 0.2131 - accuracy: 0.9120 - val_loss: 0.2490 - val_accuracy: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.1207 - accuracy: 0.9584 - val_loss: 0.4524 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "652/652 [==============================] - 137s 211ms/step - loss: 0.1038 - accuracy: 0.9618 - val_loss: 1.2709 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0998 - accuracy: 0.9628 - val_loss: 0.5046 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0917 - accuracy: 0.9711 - val_loss: 0.5266 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "652/652 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9722\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0848 - accuracy: 0.9722 - val_loss: 0.8121 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "652/652 [==============================] - 139s 214ms/step - loss: 0.0536 - accuracy: 0.9820 - val_loss: 0.0232 - val_accuracy: 1.0000 - lr: 2.5000e-05\n",
      "Epoch 8/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0463 - accuracy: 0.9837 - val_loss: 0.2293 - val_accuracy: 0.8750 - lr: 2.5000e-05\n",
      "Epoch 9/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0433 - accuracy: 0.9808 - val_loss: 0.4453 - val_accuracy: 0.8125 - lr: 2.5000e-05\n",
      "Epoch 10/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.1001 - val_accuracy: 0.9375 - lr: 2.5000e-05\n",
      "Epoch 11/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0422 - accuracy: 0.9841 - val_loss: 0.8162 - val_accuracy: 0.6875 - lr: 2.5000e-05\n",
      "Epoch 12/20\n",
      "652/652 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9864\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.5503 - val_accuracy: 0.8750 - lr: 2.5000e-05\n",
      "Epoch 13/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.3793 - val_accuracy: 0.8125 - lr: 6.2500e-06\n",
      "Epoch 14/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0245 - accuracy: 0.9902 - val_loss: 0.2799 - val_accuracy: 0.8125 - lr: 6.2500e-06\n",
      "Epoch 15/20\n",
      "652/652 [==============================] - 137s 210ms/step - loss: 0.0240 - accuracy: 0.9910 - val_loss: 0.2000 - val_accuracy: 0.9375 - lr: 6.2500e-06\n",
      "Epoch 16/20\n",
      "652/652 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9904Restoring model weights from the end of the best epoch: 7.\n",
      "652/652 [==============================] - 1369s 2s/step - loss: 0.0226 - accuracy: 0.9904 - val_loss: 0.4120 - val_accuracy: 0.9375 - lr: 6.2500e-06\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26806c53fa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.Nadam(lr=0.0001, decay=1e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_gen, epochs=50, validation_data=valid_gen, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 33s 98ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_gen, verbose=1)\n",
    "y_pred = np.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.31      0.36       234\n",
      "           1       0.64      0.75      0.69       390\n",
      "\n",
      "    accuracy                           0.58       624\n",
      "   macro avg       0.53      0.53      0.52       624\n",
      "weighted avg       0.56      0.58      0.57       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def create_df (dataset, label):\n",
    "    filenames = []  \n",
    "    labels = []\n",
    "    for file in os.listdir('./chest_xray/' + f'{dataset}/{label}'):\n",
    "        filenames.append(file)\n",
    "        labels.append(label)\n",
    "    return pd.DataFrame({'filename':filenames, 'label':labels})\n",
    "\n",
    "test_NORMAL = create_df('test', 'NORMAL')\n",
    "test_PNEUMONIA = create_df('test', 'PNEUMONIA')\n",
    "test_ori = test_NORMAL.append(test_PNEUMONIA, ignore_index=True)\n",
    "test_ori['label'] = test_ori['label'].apply(lambda x: 0 if x=='NORMAL' else 1)\n",
    "y_true = test_ori['label'].values\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
